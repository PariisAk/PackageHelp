---
title: "Package Functionalities"
output: html_document
---
There are five major functions in this package. You can read the following information for more details on each of these functions. The functionalities of some of these functions are represented by shiny app. 

1- Ticker_reader Function:
Because the first stage in any Data Science project is data acquisition and preprocessing of data for further analysis and modeling, we chose web scrapping as a method for extracting the required data, creating a user-friendly approach with a higher degree of atomization. The ticker_reader function allows users to read and get the tickers information for different companies from websites. 

2- news_sentimentanalyzer Function:
After scrapping and crawling information from news pages, by using this function users will be able to convert related links to the contents and headlines text and put them into a CSV file in a column named news. Then this function helps them to apply a lexicon and rule-based sentiment analysis tool specifically attuned to sentiments expressed in social media but proven to be quite successful when dealing with editorials and reviews. In addition to negative, neutral and positive scores that are produced for each word in the content, VADER sentiment intensity analyzer provides a compound score, which is a synthetic measure that calculates the sum of all the lexicon ratings after being normalized between -1 (most extreme negative) and +1 (most extreme positive).

3- lags Function: 
After turning the news data into something a computer can understand and use when training the LSTM network, company price data should be merged with the previously obtained scores by data, and the LSTM Neural Network models will be fitted. It should be mentioned that the class variable to be predicted is "price movement in the stock market". Time series have the additional complexity that there may be long term structure in your data that your model may not be sophisticated enough to learn. Hence, when using simple models like ARIMA, we want data to be locally stationary. lags function will consider the differences of instances as a new dataset and then produce a lagged data set to be supervised learned. 

4- normalize function:
One of the required steps for a dataset to be learned by LSTM network is to be normalized. normalize function does this for users.

5- inverter function:
After scaling the data inverter() function allows users to do inverse transformation. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

